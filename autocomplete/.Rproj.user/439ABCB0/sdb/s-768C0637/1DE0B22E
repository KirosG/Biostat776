{
    "contents" : "## Read in the data\nalltwitter <- readLines(\"en_US.twitter.txt\")\ntweets <- sample(alltwitter, round(0.05 * length(alltwitter)))  ## 5% sample\ntweets <- tolower(tweets)\n\n## Tokenize\nregex <- \"[a-z0-9']+\"\nmatches <- gregexpr(regex, tweets, perl = TRUE)\ntweetwords <- regmatches(tweets, matches)\n\n## Use 90% of vocabulary\nallwords <- unlist(tweetwords)\nprobs <- table(allwords) / length(allwords)\nprobs <- sort(probs, decreasing = TRUE)\nwords <- names(probs)\ncsum <- cumsum(probs)\nidx <- which(csum > 0.9)[1]\nuse <- seq(1, idx)\nwords <- words[use]\n\nsave(words, file = \"words.rda\")\n",
    "created" : 1445534979099.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3872913202",
    "id" : "1DE0B22E",
    "lastKnownWriteTime" : 1445527502,
    "path" : "~/Dropbox (JHU Data Science)/biostat776/autocomplete/preprocess.R",
    "project_path" : "preprocess.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_source"
}